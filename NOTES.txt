////////////////////////////////////////////////////////////////////////////////
// This document contains course notes for the course:
// "Compilers, Interpreters & Formal Languages" by Gustavo Pezzi
// https://pikuma.com/courses/create-a-programming-language-compiler
////////////////////////////////////////////////////////////////////////////////

 SECTIONS:
   #1: COURSE OVERVIEW
   #2: NOTES



  #1 | COURSE OVERVIEW:
 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
 
   [X]  #1: Introduction
            + Motivations & Learning Outcomes
            + How to Take this Course
            + Compilers as Translators
            + Your Favorite Programming Language

   [X]  #2: The Nature of Computation
            + CPU Components
            + Opcodes & Instructions
            + Stack Push & Pop
            + Control Flow
            + CPU Status Flags
            + CPU Components Quiz
            + Why the 68000?

   [X]  #3: Structure of a Program
            + What is a Program?
            + Tokens & Lexemes
            + Syntax Tree
            + Types of Compilers

   [X]  #4: Scanning Tokens
            + Setting Up our Project Folder
            + Configuring Python on Windows
            + Makefile
            + Adding Token & Lexer Files
            + Simple Scanning Algorithm
            + Single-Character Tokens
            + Ignoring Whitespace & Comments
            + Scanning Equals & Not Equals
            + Scanning Two-Char Tokens
            + Scanning Numbers
            + Why Not Just Use a RegEx?
            + Scanning Strings & Identifiers
            + Identifying Keywords
            + Stropping
            + Scanning -- as Line Comment
            + Different Languages & Comments
            + Multiline Comments
            + Watching our Memory Footprint

   [X]  #5: Parsing Expressions
            + Syntax Analysis
            + Context-Free Grammars & BNF
            + Grammar for Simple Expressions
            + A Model for AST Nodes
            + Recursive Descent Parsing
            + Parser Helper Functions (Exercise)
            + AST of a Simple Expression
            + Pretty AST Printing (Exercise)
            + AST Printing & Polish Notation
            + S-expressions

   [X]  #6: Displaying Errors
            + Terminal Colors & ANSI Escape Codes
            + Standardizing Error Messages
            + Storing Line Numbers in Nodes
            + Error Recovery Strategies
            + Renaming Term & Factor

   [X]  #7: Interpreting Expressions
            + A Tree-Walking Interpreter
            + Coding a Simple Tree-Walking Interpreter
            + No Signed Number Tokens
            + Pinky Language Data Types
            + Dynamic Types at Runtime
            + Runtime Type Checks
            + Can We Subtract Strings
            + Parsing Equality & Comparison (Exercise)
            + Parsing Equality & Comparison Operators
            + Exponent Associativity
            + Exponent & Unary Minus Precedence
            + Logical And & Logical Or
            + Short-Circuit Evaluation
            + Chained Expressions
            + Testing Expressions
            + REPL
            + Alphabets, Languages & Grammars
            + Chumsky Grammar Hierarchy

   [X]  #8: Program Statements
            + A Program as a List of Statements
            + Parsing Print Statements
            + Interpreting Print Statements
            + Automatic Semicolon Insertion
            + PrintLn Statements (Exercise)
            + PrintLn Statements & Escape Chars
            + If Statements
            + Delimiting Blocks & Dangling Else

   [X]  #9: Program State
            + Identifiers & Assignments
            + Program State & Memory
            + The Environment Class
            + To "Var or Not to "Var"?
            + Environment Load & Store (Exercise)
            + Global & Local Variables

   [X] #10: Loop Statements
            + While Statement (Exercise)
            + While Statements
            + Turing Completeness
            + For Statements
            + Stringifying Booleans & Integers
            + Mandelbrot Set (Exercise)
            + The ALGOL Family of Languages
            + Mandelbrot Set Script in Pinky
            + Compiler-Compilers

   [X] #11: Functions
            + Functions in Pinky
            + Function Model
            + Parsing Function Declaration
            + Parsing Function Call
            + Interpreting Function Declaration
            + Interpreting Function Call
            + Expressions as Statemtents?
            + Max. Number of Params (Exercise)
            + Max. Number of Params
            + Parsing Return Statements
            + Interpreting Return Statements
            + Fixing Params as Local Variables
            + Local Variables & Shadowing
            + Dragon Curve
            + Simpified Cosine & Sine Functions

   [X] #12: Code Generation
            + Code Generation & VMs
            + Example of Stack Instructions
            + Adding Classes for Compiler & VM

   [X] #13: Emitting Instructions
            + Emitting Push Instructions
            + I Was Promised Bytes!
            + Emitting BinOp Instructions
            + Formatting our Code (Exercise)
            + Formatting our Code
            + Emitting UnOp Instructions
            + Step by Step Stack Execution
            + Where are Instructions Stored?

   [X] #14: Writing a VM
            + VM Execution
            + Unpacking Argument List
            + VM Expression Evaluation
            + VM Comparison Instructions

   [X] #15: VM Jumps & Branches
            + Generating Code for If Statements
            + Generating Then & Else Labels
            + VM Jumps & Branches
            + String Concat Instruction?
            + Encoding Stack Values with C

   [X] #16: VM Memory & State
            + Global Memory Load & Store
            + Coding Globals Load & Store
            + Scope Depth
            + Starting & Ending Blocks
            + Local Variables & Stack Slots
            + Local Variables Code Generation
            + Local Variables at Runtime
            + Storing Globals by Slot Number
            + Program Symbols & Debug Info

   [X] #17: VM Loops
            + While Code Generation (Exercise)
            + Generating Code for While Statements

   [X] #18: Stack & Register VMs
            + Register vs Stack VMs
            + Register-based Bytecode
            + CPython Bytecode Disassembly
            + P-Machine & P-Code

   [X] #19: VM Subroutines
            + Search Locals in Reverse Order
            + Function Code Generation
            + Activation Frames
            + Function Symbol Tables
            + Compiling Function Declarations
            + Implementing JSR & RTS Instructions
            + Function Parameters (Exercise)
            + Validating Function Arity & Arguments
            + Frame Pointer Offsets
            + Return Statements
            + Removing Inactive Frame Slots

   [X] #20: Type Systems & Type Checkers
            + Type Systems
            + Type Annotations
            + Purposes of a Type System

   [X] #21: Bonus: Shunting Yard
            + Shunting Yard for Simple Expressions
            + Exercise: Shunting Yard Evaluation
            + A Simple Shunting Yard Evaluation
            + Shunting Yard & Parantheses
            + Shunting Yard & Right-Associativity

   [X] #22: Bonus: Pratt Parser
            + Pratt Parser
            + NUD, LED & Binding Powers
            + Example Pratt Parsing Expression
            + Pratt Code (Without Precedence)
            + Pratt Code (Precedence & Parentheses)
            + Pratt Code (Right Associativity)
            + Pratt Code (Prefix Unary Minus)

   [X] #23: Bonus: PEG
            + Parsing Expression Grammar
            + Using a PEG Library

   [X] #24: Bonus: Optimizations
            + Optimizations & Transformations
            + Constant Folding & Propagation
            + Algebraic Simplifications
            + Dead Code Elimination
            + Syntactic Sugar
            + Loop Unrolling & Inlining
            + Branch Prediction & Vectorization
            + Tail Call & Peephole Optimization

   [X] #25: Bonus: LLVM
            + LLVM IR
            + Function Definition in LLVM IR
            + Using Clang to Visualize LLVM IR
            + Integer & Float LLVM Instructions
            + SSA Form & Phi Function
            + LLVM Language Reference Manual
            + LLVM Load & Store Instructions
            + Installing Numba's llvmlite
            + Adding a Module to LLVM
            + Adding a Function to LLVM
            + Loading & Storing Variables to LLVM
            + Calling External C Functions in LLVM
            + Emit LLVM IR for a Subset of Pinky
            + Visiting AST Nodes & Emitting LLVM IR
            + Emit LLVM IR fadd Instruction
            + Emitting LLVM IR BinOps & UnOps
            + Compiling External C Print Functions
            + LLVM IR Assignments
            + Emitting LLVM for If Statements
            + Emitting LLVM IR for While Statements

   [X] #27: Conclusion & Next Steps
            + Copyright & Content Distribution
            + Similar Courses
            + Conclusion & Next Steps

   [X] COMPLETED / [-] NOT COMPLETED



  #2 | NOTES
 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
   - Course goal: Learning how to make a compiler for the pinky programming language using Python
   - Course pipeline:
     + Lexical Analysis (lexer): scanning and finding tokens
     + Syntax Analysis (parser): Formal grammars, context free grammars, PEG
     + (generated from the parser) Intermediate Representation (IR) - Abstract Syntax Tree (AST)
     + (from the AST) Interpreter
     + (from the AST) Code Generation
     + (from the AST) Type Checking
     + (from the AST) Code Optimization
    - Phase 1: Interpreter: Tokens (tokens.py) -> Lexer (lexer.py) -> Model (model.py) -> Parser (parser.py) -> Error handling -> Interpreting expressions (interpreter.py) -> Interpreting statements -> Identifiers and assignment (Environments) -> Loops (While / For) -> Functions
    - Phase 2: Compiler: Emitting Virtual Machine Instructions (compiler.py) -> Running Virtual Machine (vm.py) -> VM: Jumps and Branches (If / Else) -> VM: Storing and Loading Local / Global Variables (Memory) -> VM: Loops (While)
   
   - Structure of a program: Literals (numbers), identifiers (names), operators (assignment, comparison, grouping), keywords (reserved words), expressions (evaluates and results in a value), statements and nested statements (executes and cause a change), blocks
   
   - Binary Operator: a + b
                     /  |  \
          left operand  |  right operand
                    operator
   
   - Unary Operator: !a
                    /  \
            operator    operand
     + Prefix:  -a
     + Postfix: a--
   
   - A Tokenizer / Lexer / Scanner scans character by character of the source code, identifies the token types and generates a linear list of all the tokens in the source code
     + The token list contain information about the token type and the lexeme (token content) 
   - A parser generates the Abstract Syntax Tree (AST)
     + The AST does not worry about program correctness
     + AST can be used for type checking, optimization and code generation
   - Parser: Is the input syntactically correct?
   - Formal Grammar:
     + Defined as a set of production rules for such strings in a formal language
     + Descibes which strings from an alphabet of a formal language are valid according to the language's syntax
     + A grammar does not describe the meaning of the strings, or what can be done with the strings, only their form.
     + Formal language theory is a branch of applied mathematics (applications are found in theoretical computer science, linguistics, formal semantics, and mathematical logic)
   - Describing syntax:
     + Context-free grammars can generate context-free languages. This is done by taking a set of recursively defined variables, in terms of one another, by a set of production rules.
       + Any of the production rules in the grammar can be applied regardless of context
       + Backus-Naur form (BNF) is a formal notation for describing the syntax of a language. BNF is often used to describe context-free grammars.
         + BNF started when people from IBM where trying to define the syntax of the language ALGOL 58 and ALGOL 60
         + Defined by John Backus and Peter Naur
         + BNF can be visually represented by a syntax diagram (a.k.a. railroad diagram)
         + There are programs & tools available that can read the grammar in BNF notation and automatically generate a parser. Some examples are Lex, Yacc, Bison and ANTLR
         + There is also EBNF (Extended Backus-Naur Form) that adds some enchancements like multiple-line rules, specifiers for number of repetitions, comments, etc.
     + Parsing Expression Grammar (PEG) - A Popular alternative to context-free grammars
       + Another way of describing a formal language, but with different rules, like allowing backtracking and the order of the production matters in the interpretation
     + Grammar for simple expressions (the order matters (precedence of operators)):
       + <expr>    ::= <term> ( <addop> <term> )*
       + <term>    ::= <factor> ( <mulop> <factor> )*
       + <factor>  ::= <unary>
       + <unary>   ::= ('+'|'-'|'~') <unary> | <primary>
       + <primary> ::= <number> | '('<expr>')'
       + <addop>   ::= '+' | '-'
       + <mulop>   ::= '*' | '/'
       + <number>  ::= <digit>+
       + <digit>   ::= '0' | '1' | ... | '9'
   - For this course we'll use Recursive Descent Parsing (top-down parser)
   - And short-circuit evaluation  
   - REPL (Read Evaluate Print Loop)
   - Error Recovery Strategies:
     + Panic mode
     + Phrase-level Recovery
     + Others: error production / global correction / symbol tables
    
   - Alphabets, Languages, & Grammars
     + Alphabets & Words
       + An Alphabet is simply a set of characters, symbols, or glyphs
         + Examples:
           + A_1 = { a, b }
           + A_2 = { 0, 1 }
           + A_3 = { a, b, c, 0, 1, 2 }
       + A word is a sequence of symbols from a given alphabet. Since the example alphabets only use Unicode characters the resulting words are basically just strings.
         + Examples:
           + "abaaa"
           + "0c2a"
     + Languages, like alphabets, are also sets. But instead of being a set of single-character elements, a language is a set of strings that are formed using the characters from an alphabet.
       + Examples:
         + L_1(A_2) = { 0, 1, 01, 10, 11, 001, 010, 011, ... }  <-  (infinite)
         + L_2(A_2) = { 00, 01, 10, 11 }  <-  (finite)
     + Grammar
       + Once we start adding contraints or restrictions to a language, we form a grammar. A grammar is a set of restrictions on top of the alphabet for the given language.
       + Formally, a grammar is a tuple of 4 elements:
         + G = ( N, Σ, P, S)
           + N: non-terminals
           + Σ: terminals
           + P: productions
           + S: start symbol
       + A CFG grammar to generate simple arithmetic expressions
         + Start symbol = <expression>
         + Terminal symbols = { +, -, *, /, (, ), number}
         + Production rules:
           + <expression> -> number
           + <expression> -> (<expression>)
           + <expression> -> <expression> + <expression>
           + <expression> -> <expression> - <expression>
           + <expression> -> <expression> * <expression>
           + <expression> -> <expression> / <expression>

   - Chomsky Grammar Hierarchy
     + A hierarchy of grammars described by Noam Chomsky that contain different classes of grammars. The linguist Noam Chomasky theorized that four different classes of formal grammars existed that could generate increasingly complex languages.
        
        +-------------------------+
   0 -> |       Unrestricted      |
        | +---------------------+ |
   1 -> | |  Context-sensitive  | |
        | | +-----------------+ | |
   2 -> | | |   Context-free  | | |
        | | | +-------------+ | | |
   3 -> | | | |   Regular   | | | |
        +-+-+-+-------------+-+-+-+

       + Type 3 (Regular grammars): Commonly associated with the parsing of regular expressions and described by finite state machines (or finite automata)
       + Type 2 (Context-free grammars): Expremely popular in parsing programming languages. Context free-grammars are the main type of grammar used in this course to describe the pinky language.
       + Type 1 (Context-sensitive grammars): Used to parse both programming languages and natural languages, allowing for more complex languages than context-free grammars.
       + Type 0 (Unrestricted grammars): Includes all formal grammars. They generate exactly all languages that can be recognized by a Turing machine. Any language that is possible to be generated can be generated by a Type-0 grammar.

    + Compiler-Compilers:
      + lex - Lexer generator
      + yacc (Yet Another Compiler-Compiler) - Parser generator
      + ANTL (ANother Tool for Language Recognition) - Modern compiler-compiler
      + Other tools: Flex/Bison

    + Two types of VMs: Stack-based and register-based

    + Other types of parser (alternatives to Recursive Descent Parsing):
      + Shunting-Yard Algoritm:
        + Simple to implement
        + Good for calculators

      + Pratt Parser:
        + Operator precedence parser
        + First described by Vaughan Pratt in his 1973 paper "Top Down Operator Precedence"
        + A bit more flexible and powerful than a recursive descent parser
        + Does not rely on a formal grammar with explicit written production rules (as might be seen in a context-free grammar for a recursive descent or LR parser)
        + Instead, all we need is a stream of tokens that will be scanned using a structure encoded in NUD/LED functions and a precedence table to guide parsing
        + Flexible, easy to modify, and it can parse expressions with different operator precedence, associativity, prefix, postfix, infix, and misfix syntax
        + Works by scanning the input tokens and classifying them into two categories (functions):
          1. Operators that operate from the right with no left context
             + An example of this is the unary minus: -1
             + "Null-Denotation" or NUD
          2. Operators that operate from left-to-right with a left context
             + An example of this is a simple infox operator: 1 + 2
             + Pratt calls the specification of how an operator consumes to the right with a left-context its "Left-Denotation" or LED

      + Parsing Expression Grammar (PEG):
        + Type of formal grammar used to describe a formal language
        + Syntactically, PEGs look similar to context-free grammars and EBNF, but interpreted differently
          + The choice operator (|) is replaced by the "first match" operator (/)
          + PEGs translate EBNF to recursive descent with infinite lookahead
          + We try to match a pattern and, otherwise we backtrack
        + Examples of grammar defined in PEG format:
           expr   <- term   (('+' / '-') term)*
           term   <- factor (('*' / '/') factor)*
           factor <- / '(' + expr + ')'
           number <- [0-9]+
        + PEG parsers typically don't need a separate lexer and their productions resemble regular expressions
        + PEGs use prioritized choice to deal with ambiguities such as dangling-else, making PEG grammars unambigous
        + PEGs vs CFG:
          + PEGs inherently define deterministic grammars. The parsing process is unambigous because choices are ordered (using /). Once a match is found, the parser does not backtrack to try finding other alternatives in the same ordered choice
          + CFGs often lead to ambiguity, requiring extra mechanisms like operator precedence rules to resolve which parse tree is correct
          + PEG parsers allow for arbitrary lookahead. PEG constructs like the operators & (positive lookahead) and ! (negative lookahead) enable the parser to make decisions based on context without consuming the input
          + CFGs typically rely on finite lookahead or require more complex algorithms, like LALR og GLR parsing
        + PEG library: LPeg (Lua)

    + Code optimization & transformations:
      + Code optimimization is a transformation technique which tries to improve the intermediate code by making it consume fewer resources
      + Machine-Independent Optimization: Attempt to improve the intermediate code to get a better target code as the output. This intermediate code is transformed but it does not involve any CPU registers or absolute memory addresses
      + Machine-Dependent Optimization: Done after the target code has been generated and transformed according to the final target machine architecture. It involves CPU registers and might have absolute memory references rather than relative ones
      + Model transformations:
        + Usually happens after type checking
        + Transformations might cause the model to be "unrecognizable" when compared to the original source code, which might complicate how errors are reported
        + Optimization transformations should produce a semantically equivalent model when compared to the original source code
      + Types of optimization:
        + Constant folding & constant propagation: Pre-compute constants at compile-time
        + Algebraic Simplifications
        + Dead Code Elimination
        + Syntactic Sugar
        + Loop-Unrolling & Inlining
        + Branch Prediction
        + Vectorization
        + Tail-Call
        + Machine-Dependent & Peephole Optimization

    + LLVM:
      + Low Level Virtual Machine
      + Umbrella name for a number of software components that can be used to build compilers
      + Used to create new languages and improve existing ones
      + Generates machine code: machine-native code for a specific chip architecture
      + Optimizes code: at compile-time, link-time, runtime and idle-time
      + Standardizes the process of turning code into machine code: represents source code in a language-independent IR
      + Its flagship product is Clang, a high-end compiler
    
    + Clang follows the orthodox compiler architecture flow:
      + Frontend that parses source code into an AST and lowers it into an intermediate representation (IR)
      + Middleend optimizer that transform the IR into better IR
      + Backend that converts IR into machine code for a particular target platform/architecture

      .c -> (parser) -> AST -> (lowering) -> LLVM IR (with optimizer) -> (backend) -> Machine Code
       \                                /    \                                                  /  
         - - - - Clang Frontend - - - -        - - - - - - - - - - - LLVM - - - - - - - - - - -

                (LLVM often refers to just the optimizer & backend parts of Clang)

    + Compiler Explorer: https://godbolt.org/

    + llvmlite (LLVM Python binding):
      + https://github.com/numba/llvmlite
      + pacman -S python-llvmlite


